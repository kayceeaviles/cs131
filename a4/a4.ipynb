{"cells":[{"cell_type":"code","execution_count":3,"id":"fce907a4","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"a4 Assignment\").getOrCreate()\n","\n","path = \"gs://dataproc-staging-us-central1-265934923888-wnqace9g/datasets/2019-01-h1.csv\"\n","\n","df = spark.read.csv(path, header=True, inferSchema=True)\n","\n","df_selected = df.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\")\n","\n","df_selected.show(10)"]},{"cell_type":"code","execution_count":4,"id":"9fdf943b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- passenger_count: double (nullable = true)\n"," |-- pulocationid: double (nullable = true)\n"," |-- dolocationid: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n","\n"]}],"source":["df_selected.printSchema()\n","\n","trainDF = df_selected.sample(withReplacement=False, fraction=.8, seed=42)\n","\n","testDF = df_selected.subtract(trainDF)"]},{"cell_type":"code","execution_count":5,"id":"c499bf31","metadata":{},"outputs":[],"source":["from pyspark.ml.regression import DecisionTreeRegressor\n","\n","regressor = DecisionTreeRegressor(featuresCol=\"features\",\n","                                 labelCol=\"total_amount\")"]},{"cell_type":"code","execution_count":7,"id":"9a36cd17","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+-----------------+------------+\n","|passenger_count|pulocationid|dolocationid|         features|total_amount|\n","+---------------+------------+------------+-----------------+------------+\n","|            1.0|       151.0|       239.0|[1.0,151.0,239.0]|        9.95|\n","|            1.0|       239.0|       246.0|[1.0,239.0,246.0]|        16.3|\n","|            5.0|       193.0|       193.0|[5.0,193.0,193.0]|        7.55|\n","|            5.0|       193.0|       193.0|[5.0,193.0,193.0]|       55.55|\n","|            5.0|       193.0|       193.0|[5.0,193.0,193.0]|       13.31|\n","|            1.0|       163.0|       229.0|[1.0,163.0,229.0]|        9.05|\n","|            2.0|       141.0|       234.0|[2.0,141.0,234.0]|        13.0|\n","|            2.0|       246.0|       162.0|[2.0,246.0,162.0]|       19.55|\n","|            1.0|       238.0|       151.0|[1.0,238.0,151.0]|         8.5|\n","|            1.0|       163.0|        25.0| [1.0,163.0,25.0]|       42.95|\n","+---------------+------------+------------+-----------------+------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 3:>                                                          (0 + 1) / 1]\r","\r","                                                                                \r"]}],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","assembler = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\",\"dolocationid\"], outputCol=\"features\")\n","\n","vecTrain = assembler.transform(trainDF)\n","\n","vecTrain.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"features\", \"total_amount\").show(10)"]},{"cell_type":"code","execution_count":9,"id":"4a031ab0","metadata":{},"outputs":[],"source":["from pyspark.ml import Pipeline\n","\n","pipeline = Pipeline(stages=[assembler, regressor])"]},{"cell_type":"code","execution_count":10,"id":"3abd5bbd","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 22:>                                                         (0 + 4) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+------------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n","+---------------+------------+------------+------------+------------------+\n","|            0.0|       143.0|       141.0|        11.3|12.229978454915257|\n","|            0.0|       249.0|       231.0|        9.35|12.229978454915257|\n","|            1.0|        45.0|       186.0|        21.8|13.394432423171768|\n","|            1.0|        47.0|       140.0|       32.74|13.394432423171768|\n","|            1.0|        67.0|        22.0|         7.8|21.066133373723233|\n","|            1.0|        75.0|       142.0|       19.56|13.394432423171768|\n","|            1.0|        76.0|        17.0|        23.3|21.066133373723233|\n","|            1.0|        79.0|       236.0|       20.38|13.394432423171768|\n","|            1.0|       132.0|        79.0|       70.01|44.123787285390975|\n","|            1.0|       132.0|       152.0|       67.34| 48.95072481432126|\n","+---------------+------------+------------+------------+------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["model = pipeline.fit(trainDF)\n","\n","pred = model.transform(testDF)\n","\n","pred.select(\"passenger_count\", \"pulocationid\", \"dolocationid\", \"total_amount\", \"prediction\").show(10)"]},{"cell_type":"code","execution_count":12,"id":"c679aaee","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","regEval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"total_amount\", metricName=\"rmse\")\n","\n","rmse = regEval.evaluate(pred)"]},{"cell_type":"code","execution_count":13,"id":"10c07222","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE is: 138.4884854025505\n"]}],"source":["print(\"RMSE is:\", rmse)"]},{"cell_type":"code","execution_count":null,"id":"91c5a30b","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}